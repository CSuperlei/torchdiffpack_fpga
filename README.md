### Torchdiffpkg-FPGA

In this work, we present two techniques for acceleration of Neural-ODE inference: 1) a structured weight and activation pruning method based on top-K sparsification for the embedded NN; and 2) an adaptive stepsize search method that improves the convergence speed for reaching accepted stepsize.


